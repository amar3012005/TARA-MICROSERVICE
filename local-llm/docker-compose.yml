services:
  rag-llm-service:
    image: vllm/vllm-openai:v0.12.0
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      NVIDIA_VISIBLE_DEVICES: all
      VLLM_MAX_NUM_TOKENS: 1024
      VLLM_MAX_MODEL_LEN: 2048
      VLLM_MAX_BATCH_SIZE: 4
      VLLM_MAX_NUM_SEQS: 6
      VLLM_GPU_MEMORY_UTILIZATION: 0.7
      HUGGING_FACE_HUB_TOKEN: ${HUGGING_FACE_HUB_TOKEN:-}
    # volumes:
    #   - /home/prometheus/leibniz_models/qwen25:/models/qwen25:ro
    network_mode: "host"
    command: >-
      --model Qwen/Qwen2.5-1.5B-Instruct-AWQ
      --quantization awq
      --kv-cache-dtype fp8
      --max-num-seqs 6
      --gpu-memory-utilization 0.7
      --port 8081
    depends_on:
      - redis
    restart: unless-stopped

  redis:
    image: redis:latest
    network_mode: "host"
    # networks:
    #   - leibniz-network

# networks:
#   leibniz-network:
#     driver: bridge
