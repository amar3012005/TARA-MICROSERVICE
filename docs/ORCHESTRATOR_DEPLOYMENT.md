# StateManager Orchestrator - Complete Deployment Guide

## üöÄ Quick Start (5 Minutes)

### 1. Create Directory Structure
```bash
mkdir -p orchestrator/tests
cd orchestrator
```

### 2. Copy Implementation Files
- `state_manager.py` (from ORCHESTRATOR_IMPLEMENTATION.md)
- `app.py` (from ORCHESTRATOR_IMPLEMENTATION.md)
- `parallel_pipeline.py` (from ORCHESTRATOR_IMPLEMENTATION.md)
- `interruption_handler.py` (from ORCHESTRATOR_IMPLEMENTATION.md)

### 3. Create Supporting Files

#### `orchestrator/config.py`
```python
import os
from dataclasses import dataclass

@dataclass
class OrchestratorConfig:
    """Configuration for StateManager Orchestrator"""
    
    # Redis
    REDIS_URL: str = os.getenv("REDIS_URL", "redis://localhost:6379")
    
    # Service URLs
    INTENT_SERVICE_URL: str = os.getenv("INTENT_SERVICE_URL", "http://intent-service:8002")
    RAG_SERVICE_URL: str = os.getenv("RAG_SERVICE_URL", "http://rag-service:8003")
    STT_SERVICE_URL: str = os.getenv("STT_SERVICE_URL", "http://stt-vad-service:8001")
    
    # LLM
    LLM_PROVIDER: str = os.getenv("LLM_PROVIDER", "groq")  # groq, gemini, openai
    LLM_API_KEY: str = os.getenv("LLM_API_KEY", "")
    LLM_MODEL: str = os.getenv("LLM_MODEL", "llama-4-maverick")
    
    # TTS
    TTS_PROVIDER: str = os.getenv("TTS_PROVIDER", "elevenlabs")
    TTS_API_KEY: str = os.getenv("TTS_API_KEY", "")
    TTS_VOICE_ID: str = os.getenv("TTS_VOICE_ID", "default")
    
    # Performance
    SESSION_TTL_SECONDS: int = 3600  # 1 hour
    MAX_CONCURRENT_SESSIONS: int = 1000
    BUFFER_SIZE: int = 200  # Audio queue size
    
    # Latency targets (ms)
    INTENT_TIMEOUT_MS: int = 100
    RAG_TIMEOUT_MS: int = 150
    LLM_TIMEOUT_MS: int = 300
    TTS_TIMEOUT_MS: int = 200
    
    # Logging
    LOG_LEVEL: str = os.getenv("LOG_LEVEL", "INFO")
```

#### `orchestrator/models.py`
```python
from pydantic import BaseModel
from typing import Optional, Dict, Any, List

class STTFragment(BaseModel):
    """Message from STT service"""
    type: str
    session_id: str
    text: str
    is_final: bool
    timestamp: float

class VADEnd(BaseModel):
    """End-of-turn signal from VAD"""
    type: str
    session_id: str
    confidence: float

class OrchestrationResponse(BaseModel):
    """Response from orchestrator"""
    type: str
    session_id: str
    state: str
    text: Optional[str] = None
    latency_breakdown: Optional[Dict[str, float]] = None

class SessionMetrics(BaseModel):
    """Session metrics"""
    session_id: str
    state: str
    turn_number: int
    total_latency_ms: float
    intent_latency_ms: float
    rag_latency_ms: float
    llm_latency_ms: float
    tts_latency_ms: float
```

#### `orchestrator/requirements.txt`
```
fastapi==0.104.1
uvicorn==0.24.0
python-multipart==0.0.6
redis==5.0.1
aiohttp==3.9.1
pydantic==2.5.0
python-dotenv==1.0.0
prometheus-client==0.19.0
```

#### `orchestrator/Dockerfile`
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY . .

# Expose port
EXPOSE 8004

# Unbuffered Python for real-time logs
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1

# Health check
HEALTHCHECK --interval=10s --timeout=3s --start-period=10s --retries=3 \
    CMD python -c "import requests; requests.get('http://localhost:8004/health')" || exit 1

# Run application
CMD ["python", "-u", "app.py"]
```

---

## üê≥ Docker Compose Integration

### `docker-compose.orchestrator.yml`

```yaml
version: '3.9'

services:
  redis:
    image: redis:7-alpine
    container_name: leibniz-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    restart: unless-stopped

  # Existing STT-VAD Service
  stt-vad-service:
    build: ./services/stt-vad
    ports:
      - "8001:8001"
      - "7860:7860"
    environment:
      - REDIS_URL=redis://redis:6379
      - GEMINI_API_KEY=${GEMINI_API_KEY}
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped

  # Existing Intent Service
  intent-service:
    build: ./services/intent
    ports:
      - "8002:8002"
    environment:
      - REDIS_URL=redis://redis:6379
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped

  # Existing RAG Service
  rag-service:
    build: ./services/rag
    ports:
      - "8003:8003"
    environment:
      - REDIS_URL=redis://redis:6379
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped

  # NEW: StateManager Orchestrator
  orchestrator:
    build: ./orchestrator
    container_name: leibniz-orchestrator
    ports:
      - "8004:8004"
    environment:
      - REDIS_URL=redis://redis:6379
      - INTENT_SERVICE_URL=http://intent-service:8002
      - RAG_SERVICE_URL=http://rag-service:8003
      - STT_SERVICE_URL=http://stt-vad-service:8001
      - LLM_PROVIDER=groq
      - LLM_API_KEY=${GROQ_API_KEY}
      - TTS_PROVIDER=elevenlabs
      - TTS_API_KEY=${ELEVENLABS_API_KEY}
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=INFO
    depends_on:
      redis:
        condition: service_healthy
      stt-vad-service:
        condition: service_started
      intent-service:
        condition: service_started
      rag-service:
        condition: service_started
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8004/health"]
      interval: 10s
      timeout: 3s
      retries: 3

  # NEW: TTS Service (Optional, for streaming TTS)
  tts-service:
    build: ./services/tts
    ports:
      - "8005:8005"
    environment:
      - ELEVENLABS_API_KEY=${ELEVENLABS_API_KEY}
      - PYTHONUNBUFFERED=1
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    profiles: ["with-tts"]  # Optional service

volumes:
  redis_data:

networks:
  default:
    name: leibniz-network
```

---

## üöÄ Deployment Steps

### Step 1: Set Environment Variables
```bash
export GEMINI_API_KEY="your-gemini-key"
export GROQ_API_KEY="your-groq-key"
export ELEVENLABS_API_KEY="your-elevenlabs-key"
```

### Step 2: Build Services
```bash
docker-compose -f docker-compose.orchestrator.yml build
```

### Step 3: Start Stack
```bash
docker-compose -f docker-compose.orchestrator.yml up -d
```

### Step 4: Verify Health
```bash
# Check all services
docker-compose -f docker-compose.orchestrator.yml ps

# Expected output:
# CONTAINER ID   STATUS              PORTS
# ...            Up (healthy)        
# ...            Up (healthy)
# ...            Up (healthy)
# ...            Up (healthy)
```

### Step 5: Monitor Logs
```bash
# All services
docker-compose -f docker-compose.orchestrator.yml logs -f

# Orchestrator only
docker-compose -f docker-compose.orchestrator.yml logs -f orchestrator

# Real-time state transitions
docker-compose -f docker-compose.orchestrator.yml logs -f orchestrator | grep -E "üîµ|üü°|üî¥|‚ö°|üü¢"
```

---

## ‚úÖ Verification Tests

### Test 1: Orchestrator Health
```bash
curl -s http://localhost:8004/health | python -m json.tool
# Expected: {"status": "healthy", "active_sessions": 0, "redis_connected": true}
```

### Test 2: Create Session
```bash
python3 << 'EOF'
import asyncio
import websockets
import json

async def test():
    async with websockets.connect("ws://localhost:8004/orchestrate?session_id=test_001") as ws:
        msg = await ws.recv()
        print("‚úÖ Connected!")
        print(json.loads(msg) if msg else msg)

asyncio.run(test())
EOF
```

### Test 3: Simulate Conversation Flow
```bash
python3 << 'EOF'
import asyncio
import websockets
import json

async def simulate():
    async with websockets.connect("ws://localhost:8004/orchestrate?session_id=demo_123") as ws:
        # Step 1: Receive connected message
        await ws.recv()
        
        # Step 2: Send STT fragments
        for fragment in ["What", "are", "admission", "requirements"]:
            await ws.send(json.dumps({
                "type": "stt_fragment",
                "session_id": "demo_123",
                "text": fragment,
                "is_final": False
            }))
            await asyncio.sleep(0.5)
        
        # Step 3: Send VAD end (end-of-turn)
        await ws.send(json.dumps({
            "type": "vad_end",
            "session_id": "demo_123",
            "confidence": 0.95
        }))
        
        # Step 4: Receive response
        response = await ws.recv()
        print("Response:", json.loads(response))
        
        # Step 5: Simulate barge-in
        await ws.send(json.dumps({
            "type": "user_speaking",
            "session_id": "demo_123"
        }))
        
        # Step 6: Receive interrupt notification
        interrupt = await ws.recv()
        print("Interrupt:", json.loads(interrupt))

asyncio.run(simulate())
EOF
```

---

## üìä Monitoring & Metrics

### Prometheus Endpoint
```bash
curl http://localhost:8004/metrics
```

### Expected Metrics
```json
{
  "active_sessions": 5,
  "uptime_seconds": 3600,
  "total_turns": 42,
  "avg_latency_ms": 465,
  "errors": 0
}
```

### Docker Logs Pattern
```
orchestrator  | ======================================================================
orchestrator  | üöÄ Starting StateManager Orchestrator
orchestrator  | ======================================================================
orchestrator  | ‚úÖ Redis connected
orchestrator  | ======================================================================
orchestrator  | üîå Session connected: test_123
orchestrator  | ======================================================================
orchestrator  | üîµ IDLE ‚Üí LISTENING (stt_start)
orchestrator  | üìù [listening] STT: What are admission...
orchestrator  | ü§ê End of turn detected
orchestrator  | üìù Text: What are admission requirements
orchestrator  | ‚ö° Starting parallel Intent+RAG processing...
orchestrator  | ‚úÖ Parallel execution completed in 85ms
orchestrator  | üü° LISTENING ‚Üí THINKING (vad_end)
orchestrator  | üî¥ THINKING ‚Üí SPEAKING (response_ready)
orchestrator  | üîä Streaming TTS for: Admission requirements include...
orchestrator  | ‚úÖ TTS complete, ready for next turn
orchestrator  | üü¢ SPEAKING ‚Üí IDLE (tts_complete)
```

---

## üîß Production Optimization Checklist

- [ ] **Latency**: All state transitions < 100ms
- [ ] **Concurrency**: Tested with 100+ concurrent sessions
- [ ] **Memory**: Monitor Redis memory usage
- [ ] **Network**: All services on same Docker network
- [ ] **Logging**: Structured JSON logs to ELK
- [ ] **Monitoring**: Prometheus + Grafana dashboard
- [ ] **Alerting**: PagerDuty for critical errors
- [ ] **Load Testing**: Locust script for stress testing
- [ ] **Failover**: Redis Sentinel HA setup
- [ ] **Security**: TLS for all external connections

---

## üéØ Performance Targets

After deployment, measure:

```
Metric                          Target      Acceptable Range
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
STT ‚Üí Orchestrator              50ms        40-60ms
Parallel Intent+RAG             80ms        60-120ms
LLM Token Generation            100ms       80-150ms
TTS First Chunk                 75ms        50-100ms
TOTAL E2E Latency               465ms       400-550ms
Concurrent Sessions             1000        500-2000
Error Rate                      <0.1%       <1%
Uptime                          99.5%       >99%
```

---

## üö® Troubleshooting

### Issue: Slow Latency (>1 second)
```bash
# Check service response times
time curl -X POST http://localhost:8002/api/v1/classify -d '{"text": "test"}'
time curl -X POST http://localhost:8003/api/v1/query -d '{"query": "test"}'

# If slow, scale the service:
docker-compose -f docker-compose.orchestrator.yml up -d --scale intent-service=3
```

### Issue: "Redis connection refused"
```bash
# Verify Redis is running
docker-compose -f docker-compose.orchestrator.yml ps redis

# If not, restart
docker-compose -f docker-compose.orchestrator.yml restart redis
```

### Issue: High Memory Usage
```bash
# Check Redis memory
redis-cli INFO memory

# Clear old sessions
redis-cli FLUSHALL

# Or set aggressive TTL
# Modify SESSION_TTL_SECONDS in config.py to 300 (5 min)
```

---

## üìà Scaling

### Horizontal Scaling
```bash
# Scale orchestrator
docker-compose -f docker-compose.orchestrator.yml up -d --scale orchestrator=3

# Requires load balancer (e.g., Nginx)
```

### Vertical Scaling
```yaml
# In docker-compose.orchestrator.yml
orchestrator:
  deploy:
    resources:
      limits:
        cpus: '2'
        memory: 4G
      reservations:
        cpus: '1'
        memory: 2G
```

---

**üéâ Your StateManager Orchestrator is now production-ready!**

Next: Implement TTS integration and load testing.